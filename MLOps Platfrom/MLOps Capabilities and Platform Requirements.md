MLOps Capabilities and Platform Requirements

# Infrastructure Platform Requirements

## Amazon

https://aws.amazon.com/machine-learning/infrastructure-innovation/

- Provision of purpose-built ML accelerators
- Sustainable
- Scalable: unlimited access to:
	- compute 
	- network 
	- storage 
- support different ML frameworks:
	- TensorFlow
	- PyTorch
	- Container Images
- distributed Training jobs

- security?

## Alibaba 

https://www.alibabacloud.com/help/en/pai/product-overview/service-architecture?spm=a2c63.p38356.0.0.124d4854YEjDi5

Resource Layer:
- computing resources and infrastructure
	- CPU, GPU, Storage, Container Service for Kubernetes
	- Distributed Storage

Framework Layer:
	- support ML frameworks 

Container Support

- security?


## Google

https://cloud.google.com/ai-infrastructure
- AI accelerators
	- GPU, TPU
- Google Kuberentes or Google Compute Engine
- storage
- cpu
- network
- cost optimization with special hardware
- managed infrastructure via Vertex AI
	- setup ML environments
	- automate orchestration
	- manage large clusters
	- low latency 
- flexible hardware
- scaling via Kubernetes
- Deep Learning VMs, Containers
- features:
	- autoscaling 
	- Placement 
	- provisioning

https://cloud.google.com/solutions/ai-hypercomputer
- open software
	- tensorflow
	- pytorch 
	- max
- dynamic workload scheduler
	- access to AI/ML resources
	- flex and calender mode

- layers: 
	- Performance optimized hardware
	- open software
	- flexible consumption
		- dynamic workload scheduler
		- on demand
		- CUD 
		- Spot

https://cloud.google.com/blog/products/containers-kubernetes/google-clouds-container-platform-for-the-next-decade-of-ai

Platform requirements:
	- velocity:
	- scale:
	- efficiency goals:

Containers are well suited for AI workloads as:
	- abstract infrastructure
	- orchestrate workloads
	- support extensibility

## Microsoft

https://azure.microsoft.com/en-us/solutions/high-performance-computing/ai-infrastructure

- VMs 
- security
- 

https://microsoft.github.io/PartnerResources/assets/msa/AI%20Video.pdf

- compute resources:
	- GPU, CPU others
- high-performing storage
- fast secure networking
- workload orchestration

## Oracle
https://www.oracle.com/ai-infrastructure/
- GPU instances
- cluster of GPUs for 
- high speed networking
- high performance storage
- 


## IBM
https://www.ibm.com/ai-infrastructure

- compute resources
	- GPU
	- TPUs
- Data storage
	- cloud-based databases
	- data warehouses
	- distributed file system
- machine learning frameworks
- network 
- RedHat OpenShift as Basis
	- kubernetes 
	- containers 
	- orchestration

## The State of AI Infrastructure at Scale 2024

- Job scheduling 
- resource allocation contraints
- increase by self-served
- view and manage jobs within queues 







